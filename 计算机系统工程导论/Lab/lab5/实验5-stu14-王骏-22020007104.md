# 《计算机系统工程导论》实验报告

实验名称： MapReduce

成绩评定：

姓名：王骏

学号：220 2000 7104

专业年级： 2022级 计算机科学与技术

## *1. 实验目的*

1.  通过实验，理解MapReduce框架的基本原理，掌握MapReduce框
   架的Map阶段和Reduce阶段的执行流程，以及数据的划分、传输和
   聚合过程，具备使用MapReduce进行简单的分布式数据处理，并能
   通过进一步自学进行更为复杂的分布式数据处理，从而掌握使用
   MapReduce进行大数据处理的基本系统设计能力。
2. 通过程序验证，理解性能优化中的并发技术对时延和吞吐率的影响，
   掌握用并发技术提升系统性能的设计思想。
3. 通过观察分析，理解系统的可并行性与不可并行性的差异，理解工
   程实践中的并行不完备问题，通过思考该问题，训练理解和处理工
   程实践冲突和设计实现差异的思维能力。
4. 通过实验准备和作业提交过程中的论文查阅（MapReduce2004），
   逐步掌握外文专业文献的检索、学习和应用能力





## *2. 实验过程与习题*

### *2.1 WordCount*

*阅读程序代码，回答以下问题。*

*问题1： WordCount的__init__方法的参数是maptask和reducetask，简单地解释一下这两个变量都控制了什么*

如图1

1. **`maptask` **:
   - 这个参数控制 **Map 阶段的任务数量**。
   - 输入数据（例如，一个大文本文件）会被分割成 `maptask` 个数据块 (splits)。
   - 框架会启动 `maptask` 个 Map 任务，每个 Map 任务处理一个数据块。
2. **`reducetask` **:
   - 这个参数控制 **Reduce 阶段的任务数量**。
   - Map 任务产生的中间键值对会根据键被分区 (partitioned) 成 `reducetask` 个不同的组。
   - 框架会启动 `reducetask` 个 Reduce 任务，每个 Reduce 任务处理其中一个分区的数据。
   - `reducetask` 决定了 Reduce 阶段的并行粒度以及最终输出文件的数量。





*问题2：简要解释调用run如何触发对WordCount实例的map和reduce方法的调用。*

1. **初始化**:
   - `run` 方法首先会初始化一个进程池 (`multiprocessing.Pool`)，用于并行执行任务。
   - 它调用 `Split` 方法将输入文件（由 `self.path` 指定）分割成 `self.maptask` 个块。这些块的信息（如文件名或偏移量和大小）被准备为 Map 任务的输入。
2. **触发 Map 方法**:
   - `run` 方法准备一系列 Map 任务的参数 (`map_tasks_args`)，每个参数对应一个输入数据块。
   - 它使用进程池的 `pool.map(self.doMap, map_tasks_args)` 功能。
   - `pool.map` 会将 `self.doMap` 函数以及 `map_tasks_args` 中的每一项参数分发给进程池中的工作进程去执行。
   - `self.doMap` 是一个辅助方法，它接收 Map 任务的输入参数，然后在其内部调用用户定义的 `self.Map(key, value)` 方法。
   - 每个 Map 任务在独立的进程中执行 `WordCount.Map` 方法，处理分配给它的数据块，并产生中间键值对。
3. **Shuffle and Sort**:
   - 在所有 Map 任务完成后，`run` 方法会收集所有 Map 任务产生的中间结果。
   - 这些中间结果会根据键进行排序，并被划分 (partitioned) 成 `self.reducetask` 组，确保所有具有相同键的中间值都流向同一个 Reduce 任务。
4. **触发 Reduce 方法**:
   - `run` 方法为每个分区准备 Reduce 任务的参数 (`reduce_tasks_args`)，每个参数包含一个键和与该键相关联的所有中间值的列表。
   - 它再次使用进程池的 `pool.map(self.doReduce, reduce_tasks_args)` 功能。
   - `pool.map` 将 `self.doReduce` 函数及相应的参数分发给工作进程。
   - `self.doReduce` 是另一个辅助方法，它接收 Reduce 任务的输入（一个键和对应的值列表），然后调用用户定义的 `self.Reduce(key, values)` 方法。
   - 每个 Reduce 任务在独立的进程中执行 `WordCount.Reduce` 方法，处理分配给它的键和相关的值列表，并产生最终的输出。
5. **完成**: 所有 Reduce 任务完成后，`run` 方法结束，最终结果保存在输出文件中。

 

 

 

### *2.2 Map和Reduce*

*阅读程序代码，回答以下问题。*

*问题3：WordCount中map方法的参数keyvalue和value代表什么*

1. **`keyvalue`**:
   - 根据 `MapReduce` 基类中的 `Split` 方法的默认实现，这个 `keyvalue` 代表**输入数据块的标识符或元数据**。
2. **`value`**:
   - 这个参数代表**传递给 `Map` 任务的实际数据内容**。
   - 在 `WordCount` 场景下，`value` 通常是输入文件的一个**文本片段或行 **。
   - `Map` 方法会处理这个 `value`（字符串），将其分割成单词，并为每个单词生成一个键值对。





*问题4：WordCount中reduce方法的参数key和keyvalues代表什么？*

 在 `WordCount` 示例中，其 `Reduce` 方法定义为 `def Reduce(self, key, keyvalues):`

1. **`key`**:
   - 这个参数代表一个**唯一的键**，该键是从 Map 阶段的输出中收集并分组得到的。
2. **`keyvalues`**:
   - 这个参数是一个**list**，包含了所有与参数 `key` 相关联的来自 Map 阶段的中间值。
   - 在 `WordCount` 中，Map 阶段为每个单词出现一次就输出 `(word, 1)`。对于一个特定的单词 `key`，`keyvalues` 列表是**一系列表示计数的中间键值对**。
   - 在 `mapreduce.py` 的 `WordCount.Reduce` 实现 `return (key, sum(pair[1] for pair in keyvalues))` 中，`keyvalues` 是一个迭代器的 `(original_key, count_value)` 对，其中 `original_key` 与外部的 `key` 相同。

 

 

 

### *2.3 Map和Reduce的并行*

*问题 5: doMap有多少调用，doReduce有多少调用？为什么？*

如图2

**`doMap` 的调用次数**: 2

- `doMap` 方法的调用次数等于 `self.maptask` 的值。
- **原因**: `MapReduce` 框架的 `run` 方法首先通过 `Split` 方法将输入数据分割成 `self.maptask` 个独立的块。然后，它为每个数据块准备一个 Map 任务。`self.pool.map(self.doMap, map_tasks_args)` 会为 `map_tasks_args` 列表中的每一个元素（每个元素对应一个数据块）调用一次 `self.doMap` 方法。

**`doReduce` 的调用次数**: 2

- `doReduce` 方法的调用次数等于 `self.reducetask` 的值。
- **原因**: Map 阶段产生的中间键值对会被分区成 `self.reducetask` 个不同的组。`run` 方法会为每一个分区准备一个 Reduce 任务。`self.pool.map(self.doReduce, reduce_tasks_args)` 这行代码会为 `reduce_tasks_args` 列表中的每一个元素（每个元素对应一个分区的数据）调用一次 `self.doReduce` 方法。

 

*问题 6: 假设有足够的内核，哪些调用是并行运行的？*

**`doMap` 调用**:

- 在 Map 阶段，**多个 `doMap` 调用可以并行运行**。
- `self.pool.map(self.doMap, map_tasks_args)` 会将不同的 `doMap` 任务分配给进程池中的不同工作进程。如果 `self.maptask` 的值为 MT 且有 NC 个内核 (NC≥MT)，那么这 MT 个 `doMap` 调用可以同时执行。

**`doReduce` 调用**:

- 在 Reduce 阶段（该阶段在所有 Map 任务完成并且中间数据混洗完毕后开始），**多个 `doReduce` 调用可以并行运行**。

- `self.pool.map(self.doReduce, reduce_tasks_args)` 会将不同的 `doReduce` 任务分配给工作进程。如果 `self.reducetask` 的值为 RT 且有 NC 个内核 (NC≥RT)，那么这 RT 个 `doReduce` 调用可以同时执行。

  

*问题7：对于maptask和reducetask参数的值，哪一个影响到了程序的运行时间？为什么有的参数不会对程序的运行时间产生影响？（可以通过在代码中创建开始时间和结束时间来计算程序运行时间）*

如图3

- 增加 `maptask`:
  - **正面影响**: 如果有足够的 CPU 内核，增加 `maptask` 可以提高 Map 阶段的并行度，从而可能缩短 Map 阶段的执行时间。
  - **负面影响**: 过多的 `maptask` 会导致每个任务处理的数据量过小，增加了任务启动、调度和管理的开销。
- 减少 `maptask`:
  - **正面影响**: 减少任务管理开销。
  - **负面影响**: 降低 Map 阶段的并行度，如果 `maptask` 过小，无法充分利用多核CPU。

- 增加 `reducetask`:
  - **正面影响**: 如果有足够的 CPU 内核，增加 `reducetask` 可以提高 Reduce 阶段的并行度，从而缩短 Reduce 阶段的执行时间。
  - **负面影响**: 过多的 `reducetask` 意味着 Map 输出需要被划分到更多的分区，这可能增加shuffle的网络传输或磁盘 I/O 负担。同时，每个 Reduce 任务处理的数据量变小，可能导致任务开销占比过高。
- 减少 `reducetask`:
  - **正面影响**: 减少混洗的复杂性和输出文件的数量。
  - **负面影响**: 降低 Reduce 阶段的并行度。如果 `reducetask` 过小，Reduce 阶段将几乎是串行执行。

## *3. 遇到的问题及解决方法*

 **Map 函数逻辑错误导致词频统计不准确** 

- **遇到问题**： 最初版本的 `WordCount.Map` 函数在提取单词并计数时，发现最终统计的词频远低于预期，并且很多常见的小写单词似乎没有被统计到。例如，对于文本 "Word word Word."，期望 "word" 计数为 3 (忽略大小写和标点后)。但实际结果中 "word" 的计数非常低。

- **分析过程**： 检查 `WordCount.Map` 方法的实现：

  ```py
  class WordCount(MapReduce):
      def Map(self, keyvalue, value):
  		results = []
          n = len(value)
          i = 0
          while i < n:
              while i < n and value[i] not in string.ascii_letters: 
                  i += 1
              start = i
              while i < n and value[i] in string.ascii_letters:      
                  i += 1
              w = value[start:i]
              if start < i and w.istitle():
                  results.append ((w.lower(), 1))
          return results
  ```

  注意到 `if start < i and w.istitle():` 这一行。`w.istitle()` 方法检查单词是否为标题格式（即首字母大写，其余小写，或者全大写等特定规则）。这意味着只有符合标题格式的单词才会被计数，并且在存入结果前会被转换成小写。

- **解决方法**： 为了正确统计所有单词（不区分大小写，并去除简单的前导/尾随标点符号），需要修改 `Map` 函数中的条件判断。移除了 `w.istitle()` 的检查，确保只要提取出的字符串 `w` 是一个有效的单词（即 `start < i`），就将其转换为小写并计数。

  ```python
  w = value[start:i]
  if start < i: # 移除 w.istitle() 
  results.append ((w.lower(), 1))
  ```


## *4. 课后实验与思考（选做）*

## *5. 实验总结*

1. **理解核心概念**：认识到 `Map` 函数负责数据的并行处理和转换（将文本块映射为键值对），而 `Reduce` 函数则负责对 `Map`阶段的中间结果统计相同单词。直观地看到了数据是如何从输入分割、并行映射、混洗、再到并行规约，最终得到汇总结果的。
2. **掌握参数作用**：通过对 `WordCount` 构造函数中 `maptask` 和 `reducetask` 参数的调整与观察，理解了这两个参数如何控制 Map 任务和 Reduce 任务的数量，进而影响整个作业的并行粒度和资源分配。认识到，这些参数需要根据数据量和系统资源进行权衡。
3. **探究并行机制**：实验解释了 `run` 方法如何通过 `multiprocessing.Pool` 来调度和并行执行多个 `Map` 和 `Reduce` 任务。理解了 `doMap` 和 `doReduce` 的调用次数与 `maptask` 和 `reducetask` 直接相关，并且在有足够CPU核心的情况下，这些任务能够实现并行处理，从而加速数据处理过程。
4. **MapReduce的价值**：本次实验虽然是在单机上模拟多进程的 MapReduce，但也充分展示了其分而治之的核心思想。这种编程模型极大地简化了并行程序的开发，使开发者能够专注于 `Map` 和 `Reduce` 的业务逻辑，而不必过多纠缠于复杂的并行控制、数据分发和容错等底层细节。



## *附：实验数据与记录*

见docx附件
