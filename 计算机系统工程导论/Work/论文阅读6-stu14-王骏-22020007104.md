## **阅读：**

论文“MapReduce: Simplified Data Processing on Large Clusters”。 该论文发表在 OSDI '04上。作者来自 Google。阅读时，第 4、7 节可略过。



## **问题：**

阅读 1-3 节，能够理解和解释 Figure 1 (the "Execution overview") 。阅读 5-6 节，了解其在实际中的性能。

尝试回答这个 Hello World 问题：How do stragglers affect performance?



## 阅读过程中思考的问题：

MapReduce 的编程模式是受限的，收益值得接受这种限制吗？

MapReduce 能够处理哪些错误？它是如何处理这些错误的？

### 为讨论准备的问题（上交）：

1. 工程师提出 MapReduce 的编程模型和实现，他们的性能目标是什么？

   1. **海量数据处理**：支持TB级数据在数千台机器上高效处理（排序1TB数据仅需约15分钟）。
   2. **高吞吐量**：通过并行化和本地性优化实现高吞吐（Grep作业峰值处理速度达30GB/s）。
   3. **容错与鲁棒性**：自动处理节点故障和慢节点，确保作业完成。
   4. **简化开发**：隐藏分布式细节，降低开发门槛（索引系统代码量减少80%）。

2. Google 是怎么通过实现去满足这些目标的？

   1. **分片与并行化**：输入数据分片（M个Map任务）、中间键分区（R个Reduce任务）。
   2. **本地性优化**：Map任务优先调度到存储输入数据的节点。
   3. **备份任务**：解决长尾延迟问题。
   4. **中间数据排序**：Reduce端对中间数据排序，保证键聚合高效。
   5. **Combiner函数**：减少Shuffle数据量。

3. MapReduce 为什么选择这样实现，而没有走其他技术道路？

   1. **基础设施依赖**：基于GFS设计，利用其分块存储（64MB）和数据冗余特性。
   2. **设计权衡**
      1. **简单性优先**：选择受限模型（Map/Reduce）而非复杂模型（MPI），降低开发难度。
      2. **批处理优化**：面向离线大数据作业，非实时或迭代计算（迭代场景后来由Spark优化）。
   3. **硬件环境适配**：针对廉价商用机集群，通过冗余执行而非硬件高可用降低成本。

   

   

   

